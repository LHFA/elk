input {
    kafka {
        bootstrap_servers => "elk03:9092,elk04:9092,elk05:9092"
        topics => ["nginx_error_log"]
        codec => "json"
    }
}

filter {
    if [fields][log_topic] == "nginx_error_log" {
        grok {
            match => { "message" => "%{DATA:raw_datetime} \[%{LOGLEVEL:level}\] %{NUMBER:pid:int}#%{NUMBER}\: \*%{NUMBER} %{DATA:err_msg}, client: %{IP:client}, server: %{IPORHOST:server}, request: \"%{DATA:request}\", upstream: \"%{DATA:upstream}\", host: \"%{DATA:server_name}\""}
            match => { "message" => "%{DATA:raw_datetime} \[%{LOGLEVEL:level}\] %{NUMBER:pid:int}#%{NUMBER}\: \*%{NUMBER} %{DATA:err_msg}, client: %{IP:client}, server: %{IPORHOST:server}, request: \"%{DATA:request}\", host: \"%{DATA:server_name}\""}
            remove_field => "message"
        }
        if [request] {
            urldecode {
                field => "request"
            }
            ruby {
                init => "@kname = ['verb','url_path','httpversion']"
                code => "
                    new_event = LogStash::Event.new(Hash[@kname.zip(event.get('request').split(' '))])
                    event.append(new_event)"
           }
        }


        date {
           match => [ "raw_datetime", "YYYY/MM/dd HH:mm:ss" ]
        }

        mutate {
           remove_field  => [ "request","raw_datetime" ]
        }
    }
}

output {
    if [fields][log_topic] == "nginx_error_log" {
        elasticsearch {
            hosts => ["172.16.10.40:9200", "172.16.10.43:9200", "172.16.10.223:9200"]
            index => "nginx-error-log-%{+YYYY.MM.dd}"
            document_type => "%{[fields][document_type]}"
        }
    }
}